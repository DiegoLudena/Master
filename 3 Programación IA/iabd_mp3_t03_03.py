# -*- coding: utf-8 -*-
"""IABD_MP3_T03_03.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zGdZHCrCafssQxfYp6910MoYOlGWbzXA

•	Tarea: Construye una red neuronal convolucional (CNN) usando TensorFlow/Keras para clasificar las imágenes del dataset MNIST.
•	Requisitos:
o	Utiliza la API secuencial de Keras para definir la arquitectura de la CNN (capas convolucionales, capas de pooling y capas densas).
o	Define la función de pérdida, el optimizador y las métricas de evaluación (por ejemplo, accuracy y matriz de confusión).
o	Entrena el modelo y evalúa su rendimiento en el conjunto de prueba.
o	Puedes utilizar TensorBoard para visualizar la pérdida del modelo durante el entrenamiento.

Comenzamos instalando e importando las bibliotecas necesarias
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

import numpy as np

from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

from tensorflow.keras.callbacks import TensorBoard

"""Después, definimos la arquitectura de la CNN."""

# 1. Definir la arquitectura de la CNN

model = keras.Sequential(  #crea el modelo
    [
        keras.Input(shape=(28, 28, 1)), #Primera capa, define la entrada
        layers.Conv2D(32, kernel_size=(3, 3), activation="relu"), #primera capa convolucional
        layers.MaxPooling2D(pool_size=(2, 2)), #Reduce la dimensionalidad
        layers.Conv2D(64, kernel_size=(3, 3), activation="relu"), #segunda capa convolucional
        layers.MaxPooling2D(pool_size=(2, 2)), #Reduce la dimensionalidad
        layers.Flatten(), #transforma a vector unidimensional
        layers.Dense(10, activation="softmax"), #capa densa
    ]
)

"""Definimos las funciones para la función de pérdida, el optimizador, las métricas de evaluación (accuracy, matriz de confusión y classification report). Las métricas de evaluación necesitan una función, la función de pérdida, el optimizador y la accuracy podemos definirlas al compilar el modelo"""

# 2. Definir las funciones para  las métricas de evaluación
def calcular_matriz_confusion(y_true, y_pred):
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_true_classes = np.argmax(y_true, axis=1)
    cm = confusion_matrix(y_true_classes, y_pred_classes)
    return cm

def generar_classification_report(y_true, y_pred):
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_true_classes = np.argmax(y_true, axis=1)
    report = classification_report(y_true_classes, y_pred_classes)
    return report

# 3. Compilar el modelo
model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

"""Cargamos el dataset, lo dividimos en conjunto de entrenamiento y prueba y entrenamos al modelo."""

# 4. Entrenar el modelo
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
y_train = keras.utils.to_categorical(y_train, num_classes=10)
y_test = keras.utils.to_categorical(y_test, num_classes=10)
# Crear el callback de TensorBoard
log_dir = "logs/fit/"  # Directorio donde se guardarán los logs
tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)

# Entrenar el modelo y guardar el historial, incluyendo el callback de TensorBoard
history = model.fit(x_train, y_train, batch_size=64, epochs=10,
                    validation_split=0.1, callbacks=[tensorboard_callback])

"""Ponemos a prueba el modelo con el conjunto de prueba y calculamos las métricas de evaluación."""

# 5. Evaluar el modelo con el conjunto de prueba
score = model.evaluate(x_test, y_test, verbose=0)
print("Test loss:", score[0])
print("Test accuracy:", score[1])

# 6. Calcular la matriz de confusión y el classification report
y_pred = model.predict(x_test)
cm = calcular_matriz_confusion(y_test, y_pred)
report = generar_classification_report(y_test, y_pred)

print("Matriz de Confusión:")
# Visualizar la matriz de confusión con Seaborn
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Matriz de Confusión")
plt.xlabel("Predicciones")
plt.ylabel("Etiquetas Verdaderas")
plt.show()
print("\nClassification Report:")
print(report)

"""Para poder visualizar cómo ha ido aprendiendo el modelo, podemos utilizar tensorboard o matplotlib.
Paar usar tensorboard primero cargamos la extensión y luego la cargamos.
En ambos casos, hemos tenido que incluir en modelo, antes del entrenamiento, para que guarde los datos.
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir logs/fit

"""También podemos visualizar la pérdida y la precisión por épocas con Matplotlib, obteniendo los mismos resultados:"""

# Visualizar la pérdida
plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# Visualizar la precisión
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.show()