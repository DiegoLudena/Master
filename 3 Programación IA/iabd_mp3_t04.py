# -*- coding: utf-8 -*-
"""IABD_MP3_T04.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oLc56WjILeaea4r6sgueMuinWQK79lFD

En este tema vamos a realizar un pequeño proyecto de IA a modo de caso real. En este tema vamos a realizar un pequeño proyecto de IA a modo de caso real.

1.	Importa las librerías: Importa las librerías necesarias como pandas, numpy, scikit-learn, matplotlib y cualquier otra que necesites para el procesamiento y análisis de Big Data (por ejemplo, pyspark o dask).
"""

!pip install pyspark==3.4.1 dask[complete]==2023.6.0
!pip install matplotlib==3.5.3
!pip install ydata-profiling

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from ydata_profiling import ProfileReport

"""2.	Carga los datos: Carga el dataset utilizando pandas (o una librería de Big Data si el dataset es muy grande) y muéstralo para verificar la estructura de los datos."""

# Cargar el dataset
train_df = pd.read_csv('train.csv')

# Configurar pandas para mostrar todas las columnas
pd.set_option('display.max_columns', None)

# Mostrar las primeras filas
print(train_df.head())

# Mostrar los tipos de datos de las columnas
print(train_df.dtypes)

"""o	Estadística descriptiva: Calcula las medidas estadísticas básicas (media, desviación estándar, mínimo, máximo, etc.) de las variables."""

# Porcentaje de hombres y mujeres
gender_counts = train_df['Sex'].value_counts(normalize=True) * 100
print("Porcentaje de hombres y mujeres:")
print(gender_counts.rename({0: 'Mujeres', 1: 'Hombres'}))

# Cantidad de pasajeros por clase
class_counts = train_df['Pclass'].value_counts()
print("\nCantidad de pasajeros por clase:")
print(class_counts)

# Media de edad
mean_age = train_df['Age'].mean()
print("\nMedia de edad:", mean_age)

# Número de niños (menores de 18 años)
num_children = len(train_df[train_df['Age'] < 18])
print("\nNúmero de niños (menores de 18 años):", num_children)

# Estadísticas del precio del pasaje
fare_stats = train_df['Fare'].describe()
print("\nEstadísticas del precio del pasaje:")
print(fare_stats)

correlation = train_df['Pclass'].corr(train_df['Fare'])
print("Correlación de Pearson entre Pclass y Fare:", correlation)

# Pasajeros viajando solos vs. acompañados
train_df['TravelingAlone'] = (train_df['SibSp'] + train_df['Parch']) == 0
alone_counts = train_df['TravelingAlone'].value_counts()
print("\nPasajeros viajando solos frente a acompañados:")
print(alone_counts.rename({0: "Acompañados", 1: "Solos"}))

# Cantidad de supervivientes y fallecidos
survived_counts = train_df['Survived'].value_counts()
print("\nCantidad de supervivientes y fallecidos:")
print(survived_counts.rename({0: 'Fallecidos', 1: 'Supervivientes'}))

# Tasa de mortalidad por clase
class_mortality_rates = train_df.groupby('Pclass')['Survived'].apply(lambda x: (1 - x.mean()) * 100)
print("\nTasa de mortalidad por clase:")
print(class_mortality_rates)

# Tasa de mortalidad por género
gender_mortality_rates = train_df.groupby('Sex')['Survived'].apply(lambda x: (1 - x.mean()) * 100)
print("\nTasa de mortalidad por género:")
print(gender_mortality_rates)

# Supervivencia por edad (con grupos de edad)
# Definir los grupos de edad
bins = [0, 18, 35, 60, 100]
labels = ['Niños', 'Jóvenes', 'Adultos', 'Mayores']
train_df['AgeGroup'] = pd.cut(train_df['Age'], bins=bins, labels=labels, right=False)

# Tasa de mortalidad por edad (con grupos de edad)
age_group_mortality_rates = train_df.groupby('AgeGroup', observed=False)['Survived'].apply(lambda x: (1 - x.mean()) * 100)
print("\nTasa de mortalidad por grupo de edad:")
print(age_group_mortality_rates)

"""Toda la estadística descriptiva podríamos haberla hecha con ydata profiling:"""

# Crear el reporte
profile = ProfileReport(train_df, title="Reporte de Titanic", explorative=True)

# Mostrar el reporte en Colab
profile.to_notebook_iframe()

"""o	Visualización: Crea histogramas, diagramas de dispersión, y boxplots para visualizar las relaciones entre las variables y la variable objetivo ('Survived')."""

# Histograma de edades:
plt.figure(figsize=(8, 6))
sns.histplot(train_df['Age'], bins=20)  # Ajusta el número de bins según tus necesidades
plt.title('Distribución de la Edad')
plt.xlabel('Edad')
plt.ylabel('Frecuencia')
plt.show()

# Relación entre Class y Fare:
plt.figure(figsize=(8, 6))
sns.boxplot(x='Pclass', y='Fare', data=train_df)
plt.title('Relación entre la Clase y la Tarifa')
plt.xlabel('Clase')
plt.ylabel('Tarifa')
plt.show()

# Función para calcular y mostrar la tasa de mortalidad
def mostrar_tasa_mortalidad(grupo, titulo):
    tasa_mortalidad = train_df.groupby(grupo, observed=False)['Survived'].apply(lambda x: (1 - x.mean()) * 100)
    tasa_supervivencia = train_df.groupby(grupo, observed=False)['Survived'].apply(lambda x: (x.mean()) * 100)

    # Unir las tasas en un DataFrame para el gráfico de quesito
    data = pd.DataFrame({'Mortalidad': tasa_mortalidad, 'Supervivencia': tasa_supervivencia})

    # Colores más suaves
    colores = ['firebrick', 'forestgreen']

    for index in data.index:
        plt.figure(figsize=(4, 4))
        plt.pie(data.loc[index], labels=data.columns, autopct='%1.1f%%', colors=colores, startangle=90)
        plt.title(f'{titulo} - {index}')
        plt.show()

# Mostrar tasas de mortalidad
mostrar_tasa_mortalidad('Pclass', 'Tasa de Mortalidad por Clase')
mostrar_tasa_mortalidad('Sex', 'Tasa de Mortalidad por Género')
mostrar_tasa_mortalidad('AgeGroup', 'Tasa de Mortalidad por Grupo de Edad')

# Fallecidos por clase y por edad:

# Filtrar los datos para obtener solo los fallecidos
fallecidos_df = train_df[train_df['Survived'] == 0]

# Calcular el número de fallecidos por clase
fallecidos_por_clase = fallecidos_df['Pclass'].value_counts()

# Calcular el número de fallecidos por grupo de edad
fallecidos_por_edad = fallecidos_df['AgeGroup'].value_counts()

# Crear la figura y los subplots
fig, axes = plt.subplots(1, 2, figsize=(12, 6))

# Gráfico de quesito para fallecidos por clase
axes[0].pie(fallecidos_por_clase, labels=fallecidos_por_clase.index, autopct='%1.1f%%', colors=['firebrick', 'lightcoral', 'indianred'], startangle=90)
axes[0].set_title('Porcentaje de Fallecidos por Clase')

# Gráfico de quesito para fallecidos por grupo de edad
axes[1].pie(fallecidos_por_edad, labels=fallecidos_por_edad.index, autopct='%1.1f%%', colors=['firebrick', 'lightcoral', 'indianred', 'orangered'], startangle=90)
axes[1].set_title('Porcentaje de Fallecidos por Grupo de Edad')

plt.tight_layout()
plt.show()

# Crear una nueva columna con el número total de familiares
train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch']

# Histograma del número de familiares, con distinción entre supervivientes y fallecidos
plt.figure(figsize=(10, 6))
sns.histplot(data=train_df, x='FamilySize', hue='Survived', multiple='stack', bins=range(10))  # Ajusta bins si es necesario
plt.title('Distribución del Número de Familiares a Bordo')
plt.xlabel('Número de Familiares')
plt.ylabel('Frecuencia')
plt.legend(title='Supervivencia', labels=['Fallecidos', 'Supervivientes'])  # Ajusta etiquetas si es necesario
plt.show()

# Crear un DataFrame con la distribución de pasajeros por puerto de embarque y supervivencia
embarked_survival_distribution = train_df.groupby(['Embarked', 'Survived'])['PassengerId'].count().reset_index()
embarked_survival_distribution = embarked_survival_distribution.rename(columns={'PassengerId': 'Count'})

# Crear el gráfico de barras agrupadas
plt.figure(figsize=(8, 6))
sns.barplot(x='Embarked', y='Count', hue='Survived', data=embarked_survival_distribution)
plt.title('Distribución de Pasajeros por Puerto de Embarque y Supervivencia')
plt.xlabel('Puerto de Embarque')
plt.ylabel('Número de Pasajeros')
plt.legend(title='Supervivencia', labels=['Fallecidos', 'Supervivientes'])
plt.show()

"""Vemos que el puerto de origen parece ser un factor importante en la supervivencia. Eso llama la atención ya que debería dar igual. Es probable que sea debido a que en Southhampton embarcasen más pasajeros de 3ª clase y en Cherbourg proporcionalmente menos, vamos a estudiarlo:"""

# Crear un DataFrame con la distribución de pasajeros por puerto de embarque y clase
embarked_class_distribution = train_df.groupby(['Embarked', 'Pclass'])['PassengerId'].count().reset_index()
embarked_class_distribution = embarked_class_distribution.rename(columns={'PassengerId': 'Count'})

# Crear el gráfico de barras apiladas
plt.figure(figsize=(8, 6))
sns.barplot(x='Embarked', y='Count', hue='Pclass', data=embarked_class_distribution)
plt.title('Distribución de Pasajeros por Puerto de Embarque y Clase')
plt.xlabel('Puerto de Embarque')
plt.ylabel('Número de Pasajeros')
plt.legend(title='Clase')
plt.show()

"""Tal como habíamos supuesto hay una relación entre el puerto de embarque y la clase, que es el verdadero factor que está relacionado con la supervivencia.

o	Análisis de correlación: Calcula la matriz de correlación para identificar las variables que tienen una mayor correlación con el precio de venta.
"""

# Convertir género a numérica:
train_df['IsFemale'] = train_df['Sex'].map({'female': 1, 'male': 0})

# Seleccionar las columnas numéricas para el análisis de correlación
numeric_features = ['Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'Pclass', 'IsFemale']
correlation_data = train_df[numeric_features + ['Survived']]

# Calcular la matriz de correlación
correlation_matrix = correlation_data.corr()

# Mostrar la matriz de correlación con un heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Matriz de Correlación')
plt.show()

"""4.	Análisis de Variables: Basándote en el análisis exploratorio, identifica las características clave que influyen en el precio de venta y describe su naturaleza (numérica, categórica, ordinal, etc.).
o	¿Hay variables con valores faltantes?
o	¿Hay variables categóricas que podrían ser transformadas a numéricas?
o	¿Hay variables con una distribución sesgada o outliers?

El informe, las variables descriptivas y los gráficos que hemos sacados nos muestra que, respecto a nuestra variable objetivo que es Survived, los parámetros que tienen correlación son Gender y Pclass. Vemos también una correlación con el puerto de embarque, pero ya que este está relacionado a su vez con la clase entendemos que estudiar los dos sería redundante. Fare, por su parte, podría tener también una relación, pero, por un lado, tiene demasiados errores como para poder considerarlo (no tenemos claro qué significan los 0, podría ser que esa persona no pagó y lo hizo otra en su nombre, que era tripulación... el dataset no lo aclara), y por otro también está muy relacionado con la clase, así que tampoco es necesario estudiarla.
  El otro parámetro interesante es la edad. Tiene bastantes NaNs, pero consideramos que no los suficientes como para ignorarlo. Además, aunque en la tabla de correlación parece mostrar que no tiene relación, en realidad es por el tipo de relación que tiene: la supervivencia ni aumenta ni disminuye con la edad, si no que parece tener una distribución de campana, en que los extremos sobreviven más y las edad medias tienen mayor tasa de mortalidad.

Ta hemos transformado las variables necesarias, nos falta solamente pensar qué hacer con los NaN de la edad. Consideramos que poner la media podría estar bien, pero queremos ver primero si la edad está también relacionada con la clase. La primera idea es que probablemente en las clases más altas, que viajan por placer, sean más mayores, y en la tercera sean jóvenes o familias que buscan trabajo.
"""

# Boxplot para visualizar la distribución de la edad por clase
plt.figure(figsize=(8, 6))
sns.boxplot(x='Pclass', y='Age', data=train_df)
plt.title('Distribución de la Edad por Clase')
plt.xlabel('Clase')
plt.ylabel('Edad')
plt.show()

# Estadísticas descriptivas de la edad por clase
print(train_df.groupby('Pclass')['Age'].describe())

"""Tal como suponíamos hay una diferencia muy significativa en las edades medias. Por ello, vamos a rellenar los NaN con la media por clase."""

# Calcula la media de edad para cada clase
age_by_class = train_df.groupby('Pclass')['Age'].mean()

# Rellena los NaN de edad con la media de su clase
train_df['Age'] = train_df.apply(lambda row: age_by_class[row['Pclass']] if pd.isnull(row['Age']) else row['Age'], axis=1)

# Verifica si aún hay valores NaN en la columna 'Age'
print(train_df['Age'].isnull().sum())

"""El resto de variables hemos visto que, o bien no nos interesan para el estudio, o ya tienen una distribución correcta y no tienen blancos ni valores muy fuera de lo normal. Respecto a tener que convertir variables categóricas, solo falta Survived que se hará con un one-hot encoding al entrenar el modelo.

5.	Elección del Modelo: Basándote en el análisis de variables, decide qué tipo de modelo de regresión es más adecuado para el problema.
o	¿Un modelo lineal o un modelo no lineal?
o	¿Un modelo sencillo o un modelo más complejo como una red neuronal?
o	¿Qué modelo sería más adecuado para las características que has identificado?

Como modelo para predecir la supervivencia, ya que tenemos relaciones no lineales y algo complejas, creo que lo ideal sería una red neuronal. Sin embargo, al haber realmente pocos datos podría no ser la opción más interesante y será la opción que expliraremos en segundo lugar.
Planteamos la duda de si usar un Random Forest o SVM. Consideramos que ya que tenemos esas relaciones no lineales el Random Forest puede funcionar mejor, y será la primera opción que exploremos.

EJERCICIO 2: Modelado y Evaluación (Google Colab)
1.	Implementa el modelo: Crea el modelo de regresión elegido (basándote en la decisión del ejercicio 1) e inicializa los hiperparámetros.
2.	Entrena el modelo: Entrena el modelo con los datos de entrenamiento.
3.	Evalúa el modelo:
o	Usa métricas de regresión como el Error Cuadrático Medio (MSE), el Error Absoluto Medio (MAE), o el R-cuadrado (R²) para evaluar el rendimiento del modelo.
o	Realiza una validación cruzada para evaluar el rendimiento del modelo en diferentes subconjuntos de datos.
o	Compara los resultados con otras métricas relevantes para el problema, como el tiempo de entrenamiento.
"""

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc, classification_report

from sklearn.model_selection import cross_val_score

import time

# Define las características (X) y la variable objetivo (y)
features = ['Pclass', 'Sex', 'AgeGroup', 'SibSp', 'Parch', 'Fare', 'Embarked']
target = 'Survived'

X = pd.get_dummies(train_df[features], columns=['Sex', 'Embarked', 'AgeGroup'])  # One-hot encoding para variables categóricas
y = train_df[target]

# Divide los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crea el modelo de Random Forest
model = RandomForestClassifier(n_estimators=100, random_state=42)  # Puedes ajustar los hiperparámetros

# Entrena el modelo
model.fit(X_train, y_train)

# Realiza predicciones en el conjunto de prueba
y_pred = model.predict(X_test)

# Evalúa el rendimiento del modelo
# Calcula las métricas
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
confusion_mat = confusion_matrix(y_test, y_pred)

# Imprime las métricas
print(f"Accuracy: {accuracy}")
print(f"Precisión: {precision}")
print(f"Recuperación: {recall}")
print(f"Puntaje F1: {f1}")
print(f"Matriz de confusión:\n{confusion_mat}")

# Calcula la curva ROC y el AUC
fpr, tpr, thresholds = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)
print(f"AUC: {roc_auc}")

# Realiza la validación cruzada con 5 pliegues
scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')

# Imprime los resultados
print(f"Precisión media de la validación cruzada: {scores.mean()}")
print(f"Desviación estándar de la validación cruzada: {scores.std()}")

# Mide el tiempo de entrenamiento
start_time = time.time()
model.fit(X_train, y_train)
end_time = time.time()
training_time = end_time - start_time

print(f"Tiempo de entrenamiento: {training_time} segundos")

# Calcula la matriz de confusión
cm = confusion_matrix(y_test, y_pred)

# Visualiza la matriz de confusión con seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel("Predicción")
plt.ylabel("Valor Real")
plt.title("Matriz de Confusión")
plt.show()

"""4.	Análisis de Errores: Investiga los errores de predicción del modelo.
o	¿Cómo puedes utilizar esta información para mejorar el modelo?

Queremos ver si los errores que ha cometido el modelo han sido debidos a alguna característica más que a otra. Para ello, vamos a estudiar dónde se producen los errores, para ver si hay algún patrón.
"""

# Crea un DataFrame con las predicciones, los valores reales y las características
error_df = X_test.copy()  # Copia el DataFrame de prueba
error_df['Real'] = y_test  # Agrega la columna con los valores reales
error_df['Predicción'] = y_pred  # Agrega la columna con las predicciones del modelo
error_df['Error'] = error_df['Real'] != error_df['Predicción']  # Agrega una columna que indica si la predicción fue incorrecta

# Crea un informe del DataFrame de errores
profile = ProfileReport(error_df[error_df['Error']], title="Informe de Errores", explorative=True)

# Muestra el informe en el notebook
profile.to_notebook_iframe()

# Tasa de error por clase
error_rate_by_class = error_df.groupby('Pclass')['Error'].mean()
print(error_rate_by_class)

# Tasa de error por grupo de edad
# Obtén las columnas que representan los grupos de edad (después del one-hot encoding)
age_group_columns = [col for col in error_df.columns if col.startswith('AgeGroup_')]

# Calcula la tasa de error para cada grupo de edad
for age_group_col in age_group_columns:
    error_rate = error_df[error_df[age_group_col] == 1]['Error'].mean()
    print(f"Tasa de error para {age_group_col}: {error_rate}")

"""El análisis de errores muestra que los errores están distribuidos de forma uniforme entre las características que hemos estudiado, lo que lleva a pensar que éstas están bien elegidas y ninguna está mediendo ruido en el modelo.
El hecho de que no consiga un mayor número de éxitos puede deberse bien a que el modelo Random Forest no es el mejor para este problema o a que por las limitaciones del dataset, de pocos datos y bastantes blancos en una característica importante como es la edad, impiden que pueda tener una mayor precisión.
Vamos a intentar mejorar el resultado adaptando los hiperparámetros.

1.	Ajusta los Hiperparámetros: Experimenta con diferentes valores de los hiperparámetros del modelo (por ejemplo, la profundidad del árbol, el número de árboles en un Random Forest, etc.).
o	Compara el rendimiento del modelo antes y después de ajustar los hiperparámetros.

En lugar de ir ajustando los parámetros a mano y comparar uno a uno los resultados, podemos utilizar la biblioteca GridSearchCV sobre una serie de hiperparámetros y que compare el mejor de todos.
"""

# Crea el modelo de Random Forest
model = RandomForestClassifier(random_state=42)

# Mide el tiempo de entrenamiento inicial
start_time = time.time()
model.fit(X_train, y_train)
end_time = time.time()
initial_training_time = end_time - start_time
print(f"Tiempo de entrenamiento inicial: {initial_training_time} segundos")

# Define los hiperparámetros a ajustar y sus posibles valores
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Crea un objeto GridSearchCV
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')

# Mide el tiempo de la búsqueda de hiperparámetros
start_time = time.time()
grid_search.fit(X_train, y_train)
end_time = time.time()
grid_search_time = end_time - start_time
print(f"Tiempo de la búsqueda de hiperparámetros: {grid_search_time} segundos")

# Ajusta el modelo utilizando GridSearchCV
grid_search.fit(X_train, y_train)

# Imprime los mejores hiperparámetros encontrados
print(f"Mejores hiperparámetros: {grid_search.best_params_}")

# Obtén el mejor modelo
best_model = grid_search.best_estimator_

# Realiza predicciones en el conjunto de prueba utilizando el mejor modelo
y_pred = best_model.predict(X_test)

# Evalúa el rendimiento del mejor modelo
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
confusion_mat = confusion_matrix(y_test, y_pred)

# Imprime las métricas
print(f"Accuracy: {accuracy}")
print(f"Precisión: {precision}")
print(f"Recuperación: {recall}")
print(f"Puntaje F1: {f1}")
print(f"Matriz de confusión:\n{confusion_mat}")
# Matriz de confusión del mejor modelo
print(f"Matriz de confusión del mejor modelo:\n")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_mat, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel("Predicción")
plt.ylabel("Valor Real")
plt.title("Matriz de Confusión del Mejor Modelo")
plt.show()

# Reporte de clasificación del mejor modelo
print(f"Reporte de clasificación del mejor modelo:\n{classification_report(y_test, y_pred)}")

# Crea un DataFrame con las predicciones, los valores reales y las características para el mejor modelo
error_df = X_test.copy()
error_df['Real'] = y_test
error_df['Predicción'] = y_pred
error_df['Error'] = error_df['Real'] != error_df['Predicción']

# Crea un informe del DataFrame de errores utilizando ydata-profiling
profile = ProfileReport(error_df[error_df['Error']], title="Informe de Errores del Mejor Modelo", explorative=True)
profile.to_notebook_iframe()

"""Comparando el primer árbol con el entrenamiento hecho por GridSearchCV podemos ver que no hay una diferencia significativa en el accuracy, no ha mejorado en su capacidad de predecir correctamente la supervivencia. La precisión ha mejorado ligeramente en el modelo seleccionado por GridSearchCV (de 0.8028 a 0.8412). Esto significa que el modelo es mejor para evitar falsos positivos (predecir supervivencia cuando en realidad el pasajero falleció), pero a cambio de empeorar la recuperación (tiene más falsos negativos, marca como fallecidos pasajeros que realmente sobrevivieron), pero en realidad la diferencia es pequeña.
Con esto consideramos que, con este dataset, el modelo de Random Forest realmente no da para mucho más y habría que probar quizá modelos diferentes a ver si se consigue un mejor resultado.

2.	Prueba con Otros Modelos (Opcional): Intenta entrenar otros modelos de regresión (por ejemplo, Redes Neuronales) para comparar su rendimiento.
o	Compara el rendimiento, el tiempo de entrenamiento y la complejidad de cada modelo.

Como dijimos vamos a probar SVC. Vamos a volver a probar a buscar la mejor de entre algunas configuraciones utilizando GridSearchCV
"""

from sklearn.svm import SVC

# Crea el modelo SVM
model = SVC(random_state=42)

# Mide el tiempo de entrenamiento inicial
start_time = time.time()
model.fit(X_train, y_train)
end_time = time.time()
initial_training_time = end_time - start_time
print(f"Tiempo de entrenamiento inicial (SVM): {initial_training_time} segundos")

# Define los hiperparámetros a ajustar y sus posibles valores
param_grid = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf'],
    'gamma': ['scale', 'auto']
}

# Crea un objeto GridSearchCV
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')

# Mide el tiempo de la búsqueda de hiperparámetros
start_time = time.time()
grid_search.fit(X_train, y_train)
end_time = time.time()
grid_search_time = end_time - start_time
print(f"Tiempo de la búsqueda de hiperparámetros (SVM): {grid_search_time} segundos")

# Imprime los mejores hiperparámetros encontrados
print(f"Mejores hiperparámetros (SVM): {grid_search.best_params_}")

# Obtén el mejor modelo
best_model = grid_search.best_estimator_

# Realiza predicciones en el conjunto de prueba utilizando el mejor modelo
y_pred = best_model.predict(X_test)

# Evalúa el rendimiento del mejor modelo
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
confusion_mat = confusion_matrix(y_test, y_pred)

# Imprime las métricas
print(f"Accuracy: {accuracy}")
print(f"Precisión: {precision}")
print(f"Recuperación: {recall}")
print(f"Puntaje F1: {f1}")
print(f"Matriz de confusión:\n{confusion_mat}")

# Matriz de confusión del mejor modelo con Seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_mat, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel("Predicción")
plt.ylabel("Valor Real")
plt.title("Matriz de Confusión del Mejor Modelo (SVM)")
plt.show()

# Reporte de clasificación del mejor modelo
print(f"Reporte de clasificación del mejor modelo:\n{classification_report(y_test, y_pred)}")

"""3.	Análisis de Resultados: Compara los resultados de los diferentes modelos y selecciona el modelo que mejor rendimiento tenga para el problema.
o	Describe las características del modelo más efectivo.
o	Explica las decisiones que has tomado para elegir el modelo final.

Los resultados del mejor modelo SVM con GridSearchCV son significativamente peores que los obtenidos con Random Forest:
Random Forest:

Accuracy: 0.8268
Precisión: 0.8412
Recuperación: 0.7162
Puntaje F1: 0.7737
SVM:

Accuracy: 0.8100
Precisión: 0.8023
Recuperación: 0.7162
Puntaje F1: 0.7567
Observamos que:

Accuracy: SVM tiene una precisión general (Accuracy) menor que Random Forest (0.8100 vs 0.8268).
Precisión: SVM tiene una precisión (Precision) menor que Random Forest (0.8023 vs 0.8412).
Recuperación: La recuperación (Recall) es la misma en ambos modelos (0.7162).
Puntaje F1: SVM tiene un puntaje F1 menor que Random Forest (0.7567 vs 0.7737).
En general, las métricas indican que Random Forest está proporcionando un mejor rendimiento que SVM en este caso. Esto podría deberse a que:

Relaciones no lineales: Random Forest es capaz de manejar relaciones no lineales entre las características y la variable objetivo de forma más efectiva que SVM, especialmente con el kernel RBF.
Importancia de las características: Random Forest puede identificar automáticamente las características más importantes para la predicción, lo que puede ser útil en este problema.
Robustez: Random Forest es generalmente más robusto ante valores atípicos y ruido en los datos.

De momento el Random Forest es el mejor en todos los parámetros. Vamos a probar con una pequeña red neuronal:
"""

from sklearn.neural_network import MLPClassifier

# Crea el modelo de red neuronal
model = MLPClassifier(hidden_layer_sizes=(10, 5, 2), activation='relu', solver='adam',
                    max_iter=1000, learning_rate='adaptive', random_state=42)

# Mide el tiempo de entrenamiento
start_time = time.time()
model.fit(X_train, y_train)
end_time = time.time()
training_time = end_time - start_time
print(f"Tiempo de entrenamiento (Red Neuronal): {training_time} segundos")

# Realiza predicciones en el conjunto de prueba
y_pred = model.predict(X_test)

# Evalúa el rendimiento del modelo
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
confusion_mat = confusion_matrix(y_test, y_pred)

# Imprime las métricas
print(f"Accuracy: {accuracy}")
print(f"Precisión: {precision}")
print(f"Recuperación: {recall}")
print(f"Puntaje F1: {f1}")
print(f"Matriz de confusión:\n{confusion_mat}")

# Matriz de confusión del mejor modelo con Seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_mat, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel("Predicción")
plt.ylabel("Valor Real")
plt.title("Matriz de Confusión del Mejor Modelo (Red Neuronal)") # Cambiado el título
plt.show()

# Reporte de clasificación del mejor modelo
print(f"Reporte de clasificación del mejor modelo:\n{classification_report(y_test, y_pred)}")

"""Tras probar distintos parámetros para la red neuronal (distinto número de capas y de neuronas por capa (10), (10, 5) y (10, 10), probar otras funciones de activación (tanh y logistic) y otros optimizadores (sgd y lbfgs) hemos llegado a esta configuración, que lanza los siguientes datos, comparado con nuestro modelo ganador hasta ahora:
Accuracy: La red neuronal tiene una precisión general (Accuracy) ligeramente mayor que Random Forest (0.8324 vs 0.8268).
Precisión: Random Forest tiene una precisión (Precision) mayor que la red neuronal (0.8412 vs 0.8235). Esto significa que Random Forest es mejor para evitar falsos positivos (predecir supervivencia cuando en realidad el pasajero falleció).
Recuperación: La red neuronal tiene una recuperación (Recall) mayor que Random Forest (0.7567 vs 0.7162). Esto significa que la red neuronal es mejor para identificar a todos los pasajeros que realmente sobrevivieron (es decir, hay menos falsos negativos).
Puntaje F1: La red neuronal tiene un puntaje F1 mayor que Random Forest (0.7887 vs 0.7737). Esto indica un mejor equilibrio entre precisión y recuperación en la red neuronal.
Además, ha sido mucho más rápida de entrenar.

Por todo ello, el modelo elegido finalmente sería la red neuronal. Aunque el número de datos limitado parecía hacer pensar que no iba a tener un buen resultado, la relación compleja de los atributos con la variable objetivo finalmente ha hecho que la red neuronal de unos resultados ligeramente mejores a los del Random Forest, aunque realmente no demasiado.

4.	Despliegue (Opcional):
o	Si tienes tiempo, explora cómo se puede desplegar el modelo creado como una API (por ejemplo, usando Flask) para que pueda ser usado por otras aplicaciones.

Empezamos instalando flask e importando flask y joblib para poder guardar el modelo entrenado.
"""

import joblib

# Guarda el modelo entrenado utilizando joblib.dump()
joblib.dump(model, 'titanic_model.pkl')

"""Luego habría que crear un nuevo archivo .py, que puediese cargar el modelo titanic_model.pkl
Para ello necesitaríamos, en ese otro archivo, instalar flask e improtarlo, así como joblib para cargar el modelo.
"""

!pip install Flask

from flask import Flask, request, jsonify
import joblib

app = Flask(__name__)

# Carga el modelo entrenado
model = joblib.load('titanic_model.pkl') # Si el .pkl no está en la misma carpeta que el .py indicar la ruta

# Crea la app
@app.route('/predict', methods=['POST'])
def predict():
    data = request.get_json()  # Obtén los datos de la solicitud

    # Crea un DataFrame con los datos de entrada
    input_df = pd.DataFrame([data])

    # Realiza la predicción
    prediction = model.predict(input_df)[0]

    # Devuelve la predicción como JSON
    return jsonify({'prediction': prediction})

if __name__ == '__main__':
    app.run(debug=True)

"""Con este código, en otro archivo .py como indicamos, se podría acceder en local a la dirección y enviar la consulta en formato JSON. La API devolverá la predicción como otro JSON.
Por ejemplo, se podría mandar un JSON que fuese:
{
  "Pclass": 3,
  "Sex": "male",
  "Age": 22,
  "SibSp": 0,
  "Parch": 0,
  "Fare": 7.25,
  "Embarked": "S"
}
Y devolvería un JSON tipo
{
  "prediction": 0
}
"""

