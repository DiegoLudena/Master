# -*- coding: utf-8 -*-
"""IABD_MP4_T02_05.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pFWPk98EA-B4sCcZBqrx2Bv9j2bXIOHV

Una empresa de comercio electrónico está implementando un sistema de análisis de ventas en tiempo real. Como parte de este proyecto, necesitan asegurar la calidad de los datos que alimentarán su sistema. Se te ha proporcionado un archivo CSV llamado 'ventas_con_problemas.csv' que contiene datos de ventas de los últimos 30 días. Este archivo contiene varios problemas de calidad de datos que deben ser identificados y corregidos.Tu tarea es desarrollar un script en Python que realice las siguientes operaciones:

1.	Carga el archivo CSV y realiza una exploración inicial de los datos.
"""

# Importar las bibliotecas necesarias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar el archivo CSV
file_path = 'ventas_con_problemas_v2.csv'  # El archivo debe subirse en Colab
# Para el archivo v3, usar la línea
# file_path = 'ventas_con_problemas_v3.csv'

data = pd.read_csv(file_path)

# Guardar el número de filas originales para el informe final
filas_originales = len(data)

# Exploración inicial de los datos
# Mostrar las primeras filas del archivo para entender la estructura
print("Primeras filas del dataset:")
print(data.head())

# Describir el conjunto de datos para obtener un resumen estadístico
print("\nResumen estadístico de las columnas numéricas:")
print(data.describe())

# Información general sobre el DataFrame (tipos de datos, valores no nulos, etc.)
print("\nInformación general del DataFrame:")
print(data.info())

# Identificar valores faltantes por columna
print("\nValores faltantes por columna:")
print(data.isnull().sum())

# Identificar duplicados
print("\nNúmero de filas duplicadas:")
print(data.duplicated().sum())

"""2.	Identifica y maneja los siguientes problemas de calidad de datos:

•	Valores nulos en campos críticos (fecha, producto, cantidad, precio_unitario, total)

•	Fechas inválidas

•	Valores negativos en campos numéricos (cantidad, precio_unitario, total)

•	Inconsistencias en el cálculo del total (comparando cantidad * precio_unitario con el total registrado)

•	Valores atípicos (outliers) en campos numéricos

•	Duplicados

"""

# 1. Manejar valores nulos en campos críticos
campos_criticos = ['fecha', 'producto', 'cantidad', 'precio_unitario', 'total']

# Mostrar filas con valores nulos en campos críticos
print("Filas con valores nulos en campos críticos:")
print(data[data[campos_criticos].isnull().any(axis=1)])

valores_nulos = data[campos_criticos].isnull().sum().sum()
print(f"\nNúmero de valores nulos: {valores_nulos}")

# Los nulos en la columna cantidad, entiendo que es más probable que  sea
# un 0 mal anotado por un empleado que un error, así que se sutituyen por 0
# Guardar la cantidad de valores nulos en 'cantidad' para el informe
nulos_en_cantidad = data['cantidad'].isnull().sum()
data['cantidad'] = data['cantidad'].fillna(0)

# Los nulos en total estarían sin calcular. Se ponen a 0, y se corregirán más adelante
nulos_en_total = data['total'].isnull().sum()
data['total'] = data['total'].fillna(0)

# En las otras columnas, los valores nulos sí vamos a eliminarlos
# por no tener una forma mejor de corregirlos
campos_criticos_sin_cantidad = ['fecha', 'producto', 'precio_unitario']
# Guardar la cantidad de valores nulos en el resto de campos para el informe
nulos_en_otros_campos = data[campos_criticos_sin_cantidad].isnull().sum().sum()
data = data.dropna(subset=campos_criticos_sin_cantidad)

# 2. Manejar fechas inválidas
# Convertir la columna 'fecha' a tipo datetime y manejar errores
data['fecha'] = pd.to_datetime(data['fecha'], errors='coerce')
fechas_invalidas = data['fecha'].isnull().sum()
print(f"\nNúmero de fechas inválidas: {fechas_invalidas}")

# Eliminar filas con fechas inválidas (NaT)
data = data.dropna(subset=['fecha'])

"""Aquí pasa una cosa curiosa. Viendo a mano el documento, se observa que hay dos fechas inválidas, pero como también tienen nulos en el precio, han sido eliminados y no aparecen aquí. Si se quisieran registrar, para el informe, se podría volver a leer desde el documento, pero no lo considero necesario."""

# 3. Identificar y corregir valores negativos en cantidad y precio.
# En total no los manejo aquí, porque se corregiran con las inconsistencias
campos_numericos = ['cantidad', 'precio_unitario']
total_valores_negativos = 0
valores_negativos_por_campo = {}  # Diccionario para almacenar los valores negativos por campo

for campo in campos_numericos:
    valores_negativos = data[data[campo] < 0]
    num_negativos = (data[campo] < 0).sum()
    print(f"\nValores negativos en {campo}:")
    print(valores_negativos)
    print(f"Número de valores negativos: {num_negativos}")

    valores_negativos_por_campo[campo] = num_negativos  # Almacenar en el diccionario
    total_valores_negativos += num_negativos

    # Se podrían eliminar las filas con valores negativos, pero como ya se ha hecho en otro apartado
    # Vamos a suponer que el - es un error al pulsar el teclado y el valor es correcto
    data[campo] = data[campo].abs()

print(f"\nNúmero de valores negativos en total: {total_valores_negativos}")

# 4. Verificar y corregir inconsistencias en el cálculo del total
# Calcular el total esperado como cantidad * precio_unitario
data['total_calculado'] = data['cantidad'] * data['precio_unitario']
inconsistencias = data[data['total'] != data['total_calculado']]

# Calcular el número de inconsistencias
numero_inconsistencias = len(inconsistencias) # Corrección: Calcular el número de filas con inconsistencias

print("\nFilas con inconsistencias en el cálculo del total:")
print(inconsistencias)
print(f"\nNúmero de inconsistencias: {numero_inconsistencias}")

# Usando el valor calculado, corregir el total
data['total'] = np.where(data['total'] != data['total_calculado'], data['total_calculado'], data['total'])

# Eliminar la columna 'total_calculado' del dataset
data = data.drop(columns=['total_calculado'])

# 5. Detectar y analizar valores atípicos (outliers) en campos numéricos
# Usando el método de IQR (Rango Intercuartílico), se considerará outlier
# un dato que se aleje 1.5 veces el IQR del 1er y 3er cuartil
outliers_por_campo = {}
total_outliers = 0
for campo in ['cantidad', 'precio_unitario', 'total']:
    Q1 = data[campo].quantile(0.25)
    Q3 = data[campo].quantile(0.75)
    IQR = Q3 - Q1
    limite_inferior = Q1 - 1.5 * IQR
    limite_superior = Q3 + 1.5 * IQR

    # Calcular outliers para el campo actual
    outliers_campo = data[(data[campo] < limite_inferior) | (data[campo] > limite_superior)]
    num_outliers = len(outliers_campo)  # Obtener el número de outliers

    outliers_por_campo[campo] = num_outliers  # Almacenar en el diccionario
    total_outliers += num_outliers  # Sumar al total general

    print(f"\nValores atípicos en {campo}:")
    print(outliers_campo)
    print(f"Número de valores atípicos: {num_outliers}")

"""Al no tener una referencia de qué son los productos o a qué se dedica la tienda, realmente no sabemos cómo manejar los outliers. Quizá sea una tienda muy generalista, con productos con precios y stock muy variados y estén bien. En ese caso, se podría ajustar más el límite inferior y superior para que fuesen más permisivos, y hubiese menos outliers."""

# 6. Eliminar filas duplicadas
num_duplicados = data.duplicated().sum()
print(f"\nNúmero de filas duplicadas: {num_duplicados}")

# Eliminar filas duplicadas
data = data.drop_duplicates()

# Mostrar un resumen final de los datos limpios
print("\nDatos limpios:")
print(data.head())

"""4.	Genera un informe que incluya:

•	Número de filas originales vs. número de filas después de la limpieza

•	Cantidad de problemas identificados y corregidos por cada tipo

•	Estadísticas descriptivas de los datos limpios (media, mediana, desviación estándar) para campos numéricos

"""

# Informe de limpieza de datos
filas_limpias = len(data)

print("Informe de Limpieza de Datos")
print("---------------------------")
print(f"Número de filas originales: {filas_originales}")
print(f"Número de filas después de la limpieza: {filas_limpias}")
print(f"Filas eliminadas: {filas_originales - filas_limpias}")
print(f"Porcentaje de filas eliminadas: {(filas_originales - filas_limpias) / filas_originales * 100:.2f}%")

print("Problemas identificados y corregidos:")
print(f"- Valores nulos en campos críticos: {valores_nulos}")
print(f"- Valores nulos en cantidad (sustituidos por 0): {nulos_en_cantidad}")
print(f"- Valores nulos en total (sustituidos por 0): {nulos_en_total}")
print(f"- Valores nulos en otros campos (eliminados): {nulos_en_otros_campos}")

print(f"- Fechas inválidas: {fechas_invalidas}")
print(f"- Valores negativos:")
for campo, num_negativos in valores_negativos_por_campo.items():  # Iterar sobre el diccionario
    print(f"  * {campo}: {num_negativos}")
print(f"- Total valores negativos: {total_valores_negativos}")
print(f"- Inconsistencias en el cálculo del total: {numero_inconsistencias}")
print(f"- Valores atípicos:")
for campo, num_outliers in outliers_por_campo.items():  # Iterar sobre el diccionario
    print(f"  * {campo}: {num_outliers}")
print(f"- Total valores atípicos: {total_outliers}")
print(f"- Filas duplicadas: {num_duplicados}\n")

# Estadísticas descriptivas de los datos limpios
print("Estadísticas descriptivas de los datos limpios:")
print(data[['cantidad', 'precio_unitario', 'total']].describe())

"""5.	Crea visualizaciones que ayuden a entender la distribución de los datos y los efectos de la limpieza.

Histogramas para visualizar la distribución de los datos antes y después de la limpieza. Permite observar si la limpieza ha afectado la forma de la distribución, si se han eliminado valores atípicos, etc.
"""

# Antes de la limpieza
data_original = pd.read_csv(file_path)

plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
sns.histplot(data_original['cantidad'], kde=True)  # data_original es el dataset antes de la limpieza
plt.title('Cantidad (Antes)')
plt.subplot(1, 3, 2)
sns.histplot(data_original['precio_unitario'], kde=True)
plt.title('Precio Unitario (Antes)')
plt.subplot(1, 3, 3)
sns.histplot(data_original['total'], kde=True)
plt.title('Total (Antes)')
plt.show()

# Después de la limpieza
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
sns.histplot(data['cantidad'], kde=True)  # data es el dataset después de la limpieza
plt.title('Cantidad (Después)')
plt.subplot(1, 3, 2)
sns.histplot(data['precio_unitario'], kde=True)
plt.title('Precio Unitario (Después)')
plt.subplot(1, 3, 3)
sns.histplot(data['total'], kde=True)
plt.title('Total (Después)')
plt.show()

"""Los diagramas de caja son útiles para visualizar la distribución de los datos, identificar valores atípicos y comparar la distribución antes y después de la limpieza."""

# Antes de la limpieza
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
sns.boxplot(x=data_original['cantidad'])
plt.title('Cantidad (Antes)')
plt.subplot(1, 3, 2)
sns.boxplot(x=data_original['precio_unitario'])
plt.title('Precio Unitario (Antes)')
plt.subplot(1, 3, 3)
sns.boxplot(x=data_original['total'])
plt.title('Total (Antes)')
plt.show()

# Después de la limpieza
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
sns.boxplot(x=data['cantidad'])
plt.title('Cantidad (Después)')
plt.subplot(1, 3, 2)
sns.boxplot(x=data['precio_unitario'])
plt.title('Precio Unitario (Después)')
plt.subplot(1, 3, 3)
sns.boxplot(x=data['total'])
plt.title('Total (Después)')
plt.show()

"""Uniendo un poco ambos, sale el diagrama de violín, que combina la caja en pequeño y la densidad de los datos en cada punto de la distribución."""

# Antes de la limpieza
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
sns.violinplot(x=data_original['cantidad'])
plt.title('Cantidad (Antes)')
plt.subplot(1, 3, 2)
sns.violinplot(x=data_original['precio_unitario'])
plt.title('Precio Unitario (Antes)')
plt.subplot(1, 3, 3)
sns.violinplot(x=data_original['total'])
plt.title('Total (Antes)')
plt.show()

# Después de la limpieza
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
sns.violinplot(x=data['cantidad'])
plt.title('Cantidad (Después)')
plt.subplot(1, 3, 2)
sns.violinplot(x=data['precio_unitario'])
plt.title('Precio Unitario (Después)')
plt.subplot(1, 3, 3)
sns.violinplot(x=data['total'])
plt.title('Total (Después)')
plt.show()

""" Un gráfico de barras para mostrar la cantidad de problemas identificados y corregidos por cada tipo (valores nulos, fechas inválidas, valores negativos, inconsistencias, valores atípicos, duplicados). Esto permitirá visualizar el impacto de cada paso de la limpieza."""

problemas = ['Nulos', 'Fechas inválidas', 'Negativos', 'Inconsistencias', 'Outliers', 'Duplicados']
cantidades = [valores_nulos, fechas_invalidas, total_valores_negativos, numero_inconsistencias, total_outliers, num_duplicados]

plt.figure(figsize=(10, 6))
sns.barplot(x=problemas, y=cantidades)
plt.title('Problemas identificados y corregidos')
plt.xlabel('Tipo de problema')
plt.ylabel('Cantidad')
plt.show()

"""Este gráfico de barras muestra dónde estaban los negativos, los dulpicados y los valores nulos. No muestra las fechas inválidas ni las inconsistencias, porque por fuerza estarán en fecha y en total respectivamente."""

# Gráfico de Barras Apilado de Problemas de Calidad por Columna
# Ajustar el diccionario problemas_calidad para que todas las listas tengan la misma longitud
# Obtener el número de columnas
num_columnas = len(data_original.columns)

# Construir el diccionario con listas de longitud uniforme
problemas_calidad = {
    'Valores Nulos': data_original.isnull().sum().tolist(),
    'Valores Negativos': [(data_original[campo] < 0).sum() if campo in data_original.select_dtypes(include=np.number).columns else 0 for campo in data_original.columns],
    'Duplicados': [data_original.duplicated().sum()] + [0] * (num_columnas - 1)  # Solo el primer valor muestra duplicados
}

# Convertir el diccionario a DataFrame
problemas_df = pd.DataFrame(problemas_calidad, index=data_original.columns)

# Graficar el DataFrame de problemas de calidad
problemas_df.plot(kind='bar', stacked=True, figsize=(12, 6), color=['skyblue', 'salmon', 'lightgreen'])
plt.title("Problemas de Calidad de Datos por Columna (Original)")
plt.xlabel("Columnas")
plt.ylabel("Número de Problemas")
plt.xticks(rotation=45)
plt.legend(title="Tipo de Problema")
plt.show()

"""Con este mapa de calor se puede visualizar dónde estaban los valores nulos"""

# Heatmap de valores faltantes en el dataset original
plt.figure(figsize=(10, 6))
sns.heatmap(data_original.isnull(), cbar=False, cmap='viridis')
plt.title("Mapa de Calor de Valores Faltantes en Datos Originales")
plt.xlabel("Columnas")
plt.ylabel("Filas")
plt.show()

"""Con los datos ya limpios, se pueden hacer distintas gráficas para estudiarlos, por ejemplo:

Tendencia temporal de ventas, que muestra la suma de ventas diarias en el tiempo, permitiendo observar cómo las ventas fluctúan a lo largo del tiempo antes y después de la limpieza.
"""

#Hay que volver a asegurar que la fecha original esté en formato válido
data_original['fecha'] = pd.to_datetime(data_original['fecha'], errors='coerce')
data['fecha'] = pd.to_datetime(data['fecha'], errors='coerce')
ventas_diarias_original = data_original.groupby('fecha')['total'].sum()
ventas_diarias_limpio = data.groupby('fecha')['total'].sum()

plt.figure(figsize=(14, 6))
plt.plot(ventas_diarias_original.index, ventas_diarias_original.values, label='Original', color='skyblue')
plt.plot(ventas_diarias_limpio.index, ventas_diarias_limpio.values, label='Limpio', color='salmon')
plt.title('Tendencia de ventas diarias antes y después de la limpieza')
plt.xlabel('Fecha')
plt.ylabel('Ventas Totales')
plt.legend()
plt.show()

"""Un boxplot que muestra el volumen de ventas por día de la semana."""

# Crear una columna con el día de la semana
data['dia_semana'] = data['fecha'].dt.day_name()
# Como day_name() pone el nombre en ingles, crear un diccionario de traducción
dias_semana_traducidos = {
    'Monday': 'Lunes', 'Tuesday': 'Martes', 'Wednesday': 'Miércoles',
    'Thursday': 'Jueves', 'Friday': 'Viernes', 'Saturday': 'Sábado', 'Sunday': 'Domingo'
}
# Reemplazar los nombres de los días con su traducción
data['dia_semana'] = data['dia_semana'].replace(dias_semana_traducidos)

# Crear el boxplot con días en español
plt.figure(figsize=(10, 6))
sns.boxplot(data=data, x='dia_semana', y='total',
            order=['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo'])
plt.title("Distribución de Ventas por Día de la Semana")
plt.xlabel("Día de la Semana")
plt.ylabel("Ventas Totales")
plt.show()

"""Un gráfico de barras para saber qué producto es el que más ingresos deja."""

# Gráfico de barras: Distribución de ingresos por producto
ventas_por_producto = data.groupby('producto')['total'].sum().sort_values()
plt.figure(figsize=(10, 6))
ventas_por_producto.plot(kind='barh', color='green')
plt.title("Distribución de ingresos totales por producto")
plt.xlabel("Ventas Totales")
plt.ylabel("Producto")
plt.show()

"""Guarda los datos limpios en un nuevo archivo CSV.

"""

# Guardar los datos limpios en un nuevo archivo CSV
data.to_csv('ventas_limpias_v2.csv', index=False)

# Para el archivo v3, usar la línea
# data.to_csv('ventas_limpias_v3.csv', index=False)